{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sized-headset",
   "metadata": {},
   "source": [
    "# lightGBM part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parental-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "detected-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         441\n",
       "1         841\n",
       "2         361\n",
       "3         289\n",
       "4        2209\n",
       "         ... \n",
       "11895     529\n",
       "11896     961\n",
       "11897     441\n",
       "11898     841\n",
       "11899     289\n",
       "Name: age, Length: 11900, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(base_train['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "hybrid-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age-median</th>\n",
       "      <th>education-num-median</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education-num  marital-status  occupation  \\\n",
       "0   21          3         13             10               0           1   \n",
       "1   29          3         10              9               0           1   \n",
       "2   19          3          9             13               2           8   \n",
       "3   17          3         10              9               2           2   \n",
       "4   47          3         13             10               1           2   \n",
       "\n",
       "   relationship  race  sex  age-median  education-num-median  Y  \n",
       "0             3     2    0        -3.0                   0.0  0  \n",
       "1             1     2    0         5.0                  -1.0  0  \n",
       "2             1     2    0        -5.0                   3.0  0  \n",
       "3             3     2    1        -7.0                  -1.0  0  \n",
       "4             0     2    1        23.0                   0.0  0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train = pd.read_csv('data/train2.csv')\n",
    "base_test = pd.read_csv('data/test2.csv')\n",
    "\n",
    "base_train = base_train.drop('index', axis=1)\n",
    "base_train = base_train.drop('native-country', axis=1)\n",
    "base_train = base_train.drop('fnlwgt', axis=1)\n",
    "# base_train = base_train.drop('race', axis=1)\n",
    "\n",
    "base_test = base_test.drop('index', axis=1)\n",
    "base_test = base_test.drop('native-country', axis=1)\n",
    "base_test = base_test.drop('fnlwgt', axis=1)\n",
    "# base_test = base_test.drop('race', axis=1)\n",
    "\n",
    "\n",
    "# 特徴量の追加\n",
    "\n",
    "base_train['age-median'] = base_train['age'] - base_train['age'].median()\n",
    "# base_train['age-mean'] = base_train['age'] - base_train['age'].mean()\n",
    "# base_train['age-square'] = np.square(base_train['age'])\n",
    "base_train['education-num-median'] = base_train['education-num'] - base_train['education-num'].median()\n",
    "\n",
    "base_test['age-median'] = base_test['age'] - base_train['age'].median()\n",
    "# base_test['age-mean'] = base_test['age'] - base_train['age'].mean()\n",
    "# base_test['age-square'] = np.square(base_test['age'])\n",
    "base_test['education-num-median'] = base_test['education-num'] - base_train['education-num'].median()\n",
    "\n",
    "# \"Y\"の順序\n",
    "cols = base_train.columns.tolist()\n",
    "cols.remove(\"Y\")\n",
    "cols.append(\"Y\")\n",
    "base_train = base_train[cols]\n",
    "\n",
    "base_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "distant-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# categorical_features = [\"workclass\",\"fnlwgt\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n",
    "categorical_features = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\"]\n",
    "cat_columns = []\n",
    "for i,v in enumerate(base_train.columns):\n",
    "    if v in categorical_features:\n",
    "        cat_columns.append(i)\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-holocaust",
   "metadata": {},
   "source": [
    "### ハイパラメータ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "continent-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(base_train.iloc[:,:-1],base_train.iloc[:,-1], random_state=0, test_size=0.2)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "static-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-16 23:03:58,213]\u001b[0m A new study created in memory with name: no-name-9e434b71-7ee8-4695-b88d-211b79cad1f2\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: -inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  14%|#4        | 1/7 [00:00<00:02,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:03:58,602]\u001b[0m Trial 0 finished with value: 0.9105910024140965 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.9105910024140965.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  14%|#4        | 1/7 [00:00<00:02,  2.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  14%|#4        | 1/7 [00:00<00:02,  2.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  29%|##8       | 2/7 [00:00<00:01,  2.79it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:03:58,965]\u001b[0m Trial 1 finished with value: 0.9099056923042212 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.9105910024140965.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  29%|##8       | 2/7 [00:00<00:01,  2.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  29%|##8       | 2/7 [00:01<00:01,  2.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  43%|####2     | 3/7 [00:01<00:01,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:03:59,332]\u001b[0m Trial 2 finished with value: 0.9092232024005595 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.9105910024140965.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  43%|####2     | 3/7 [00:01<00:01,  2.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  43%|####2     | 3/7 [00:01<00:01,  2.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  57%|#####7    | 4/7 [00:01<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:03:59,720]\u001b[0m Trial 3 finished with value: 0.9105289578774 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.9105910024140965.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910591:  57%|#####7    | 4/7 [00:01<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  57%|#####7    | 4/7 [00:01<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  71%|#######1  | 5/7 [00:01<00:00,  2.62it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:00,127]\u001b[0m Trial 4 finished with value: 0.9106953500439953 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.9106953500439953.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  71%|#######1  | 5/7 [00:01<00:00,  2.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  71%|#######1  | 5/7 [00:02<00:00,  2.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  86%|########5 | 6/7 [00:02<00:00,  2.58it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:00,515]\u001b[0m Trial 5 finished with value: 0.9093811339485143 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.9106953500439953.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  86%|########5 | 6/7 [00:02<00:00,  2.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695:  86%|########5 | 6/7 [00:02<00:00,  2.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910695: 100%|##########| 7/7 [00:02<00:00,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:00,945]\u001b[0m Trial 6 finished with value: 0.9095306048778287 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.9106953500439953.\u001b[0m\n",
      "feature_fraction, val_score: 0.910695: 100%|##########| 7/7 [00:02<00:00,  2.58it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:   5%|5         | 1/20 [00:00<00:11,  1.67it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:01,574]\u001b[0m Trial 7 finished with value: 0.9102300160187713 and parameters: {'num_leaves': 34}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:   5%|5         | 1/20 [00:00<00:11,  1.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:   5%|5         | 1/20 [00:01<00:11,  1.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  10%|#         | 2/20 [00:01<00:12,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:02,381]\u001b[0m Trial 8 finished with value: 0.9066483541276538 and parameters: {'num_leaves': 135}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  10%|#         | 2/20 [00:01<00:12,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  10%|#         | 2/20 [00:01<00:12,  1.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  15%|#5        | 3/20 [00:01<00:10,  1.58it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:02,905]\u001b[0m Trial 9 finished with value: 0.906625792477946 and parameters: {'num_leaves': 121}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  15%|#5        | 3/20 [00:01<00:10,  1.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  15%|#5        | 3/20 [00:02<00:10,  1.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  20%|##        | 4/20 [00:02<00:08,  1.91it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:03,267]\u001b[0m Trial 10 finished with value: 0.9097675021997609 and parameters: {'num_leaves': 29}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  20%|##        | 4/20 [00:02<00:08,  1.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  20%|##        | 4/20 [00:02<00:08,  1.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  25%|##5       | 5/20 [00:02<00:08,  1.86it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:03,834]\u001b[0m Trial 11 finished with value: 0.9070234415540465 and parameters: {'num_leaves': 81}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  25%|##5       | 5/20 [00:02<00:08,  1.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  25%|##5       | 5/20 [00:03<00:08,  1.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  30%|###       | 6/20 [00:03<00:09,  1.54it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:04,704]\u001b[0m Trial 12 finished with value: 0.9060645714414638 and parameters: {'num_leaves': 223}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  30%|###       | 6/20 [00:03<00:09,  1.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  30%|###       | 6/20 [00:04<00:09,  1.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  35%|###5      | 7/20 [00:04<00:10,  1.29it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:05,728]\u001b[0m Trial 13 finished with value: 0.9060476502041829 and parameters: {'num_leaves': 211}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  35%|###5      | 7/20 [00:04<00:10,  1.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  35%|###5      | 7/20 [00:05<00:10,  1.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  40%|####      | 8/20 [00:05<00:09,  1.25it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:06,588]\u001b[0m Trial 14 finished with value: 0.9060532906166099 and parameters: {'num_leaves': 228}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  40%|####      | 8/20 [00:05<00:09,  1.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  40%|####      | 8/20 [00:06<00:09,  1.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  45%|####5     | 9/20 [00:06<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:07,098]\u001b[0m Trial 15 finished with value: 0.9048490625634547 and parameters: {'num_leaves': 133}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  45%|####5     | 9/20 [00:06<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  45%|####5     | 9/20 [00:06<00:07,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  50%|#####     | 10/20 [00:06<00:06,  1.52it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:07,635]\u001b[0m Trial 16 finished with value: 0.9072462378449112 and parameters: {'num_leaves': 130}. Best is trial 7 with value: 0.9102300160187713.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910695:  50%|#####     | 10/20 [00:06<00:06,  1.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  50%|#####     | 10/20 [00:06<00:06,  1.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  55%|#####5    | 11/20 [00:06<00:04,  1.86it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:07,906]\u001b[0m Trial 17 finished with value: 0.9116429393317239 and parameters: {'num_leaves': 9}. Best is trial 17 with value: 0.9116429393317239.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  55%|#####5    | 11/20 [00:06<00:04,  1.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  55%|#####5    | 11/20 [00:07<00:04,  1.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  60%|######    | 12/20 [00:07<00:04,  1.65it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:08,665]\u001b[0m Trial 18 finished with value: 0.9113552782979492 and parameters: {'num_leaves': 2}. Best is trial 17 with value: 0.9116429393317239.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911643:  60%|######    | 12/20 [00:07<00:04,  1.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  60%|######    | 12/20 [00:08<00:04,  1.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  65%|######5   | 13/20 [00:08<00:03,  1.81it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:09,097]\u001b[0m Trial 19 finished with value: 0.9118516345915213 and parameters: {'num_leaves': 3}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  65%|######5   | 13/20 [00:08<00:03,  1.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  65%|######5   | 13/20 [00:08<00:03,  1.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  70%|#######   | 14/20 [00:08<00:02,  2.08it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:09,413]\u001b[0m Trial 20 finished with value: 0.9117472869616227 and parameters: {'num_leaves': 10}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  70%|#######   | 14/20 [00:08<00:02,  2.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  70%|#######   | 14/20 [00:08<00:02,  2.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  75%|#######5  | 15/20 [00:08<00:02,  2.19it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:09,807]\u001b[0m Trial 21 finished with value: 0.9084194436297182 and parameters: {'num_leaves': 62}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  75%|#######5  | 15/20 [00:08<00:02,  2.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  75%|#######5  | 15/20 [00:09<00:02,  2.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  80%|########  | 16/20 [00:09<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:10,245]\u001b[0m Trial 22 finished with value: 0.9087437673442682 and parameters: {'num_leaves': 80}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  80%|########  | 16/20 [00:09<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  80%|########  | 16/20 [00:09<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  85%|########5 | 17/20 [00:09<00:01,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:10,650]\u001b[0m Trial 23 finished with value: 0.9118516345915213 and parameters: {'num_leaves': 3}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  85%|########5 | 17/20 [00:09<00:01,  2.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  85%|########5 | 17/20 [00:10<00:01,  2.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  90%|######### | 18/20 [00:10<00:01,  1.99it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:11,309]\u001b[0m Trial 24 finished with value: 0.9053990027750829 and parameters: {'num_leaves': 181}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  90%|######### | 18/20 [00:10<00:01,  1.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  90%|######### | 18/20 [00:10<00:01,  1.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  95%|#########5| 19/20 [00:10<00:00,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:11,651]\u001b[0m Trial 25 finished with value: 0.9085378922906843 and parameters: {'num_leaves': 43}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  95%|#########5| 19/20 [00:10<00:00,  2.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852:  95%|#########5| 19/20 [00:11<00:00,  2.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911852: 100%|##########| 20/20 [00:11<00:00,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:12,106]\u001b[0m Trial 26 finished with value: 0.9065440064977551 and parameters: {'num_leaves': 98}. Best is trial 19 with value: 0.9118516345915213.\u001b[0m\n",
      "num_leaves, val_score: 0.911852: 100%|##########| 20/20 [00:11<00:00,  1.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911852:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:  10%|#         | 1/10 [00:00<00:04,  2.25it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:12,570]\u001b[0m Trial 27 finished with value: 0.9132955801728222 and parameters: {'bagging_fraction': 0.4020487177385277, 'bagging_freq': 3}. Best is trial 27 with value: 0.9132955801728222.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:  10%|#         | 1/10 [00:00<00:04,  2.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:  10%|#         | 1/10 [00:00<00:04,  2.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:  20%|##        | 2/10 [00:00<00:03,  2.11it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:13,064]\u001b[0m Trial 28 finished with value: 0.9129515150147779 and parameters: {'bagging_fraction': 0.9199766373049231, 'bagging_freq': 3}. Best is trial 27 with value: 0.9132955801728222.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913296:  20%|##        | 2/10 [00:00<00:03,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  20%|##        | 2/10 [00:01<00:03,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  30%|###       | 3/10 [00:01<00:04,  1.71it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:13,790]\u001b[0m Trial 29 finished with value: 0.9134563319269905 and parameters: {'bagging_fraction': 0.8673290129766871, 'bagging_freq': 3}. Best is trial 29 with value: 0.9134563319269905.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  30%|###       | 3/10 [00:01<00:04,  1.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  30%|###       | 3/10 [00:01<00:04,  1.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  40%|####      | 4/10 [00:01<00:02,  2.27it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:14,000]\u001b[0m Trial 30 finished with value: 0.9101538704510074 and parameters: {'bagging_fraction': 0.47022576881430145, 'bagging_freq': 6}. Best is trial 29 with value: 0.9134563319269905.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  40%|####      | 4/10 [00:01<00:02,  2.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  40%|####      | 4/10 [00:02<00:02,  2.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  50%|#####     | 5/10 [00:02<00:02,  2.14it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:14,520]\u001b[0m Trial 31 finished with value: 0.9123846535658687 and parameters: {'bagging_fraction': 0.7401473830219293, 'bagging_freq': 5}. Best is trial 29 with value: 0.9134563319269905.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913456:  50%|#####     | 5/10 [00:02<00:02,  2.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  50%|#####     | 5/10 [00:02<00:02,  2.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  60%|######    | 6/10 [00:02<00:01,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:14,937]\u001b[0m Trial 32 finished with value: 0.9136227240935857 and parameters: {'bagging_fraction': 0.8289667839436456, 'bagging_freq': 7}. Best is trial 32 with value: 0.9136227240935857.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  60%|######    | 6/10 [00:02<00:01,  2.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  60%|######    | 6/10 [00:03<00:01,  2.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  70%|#######   | 7/10 [00:03<00:01,  2.30it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:15,336]\u001b[0m Trial 33 finished with value: 0.9134224894524288 and parameters: {'bagging_fraction': 0.6110859577961836, 'bagging_freq': 5}. Best is trial 32 with value: 0.9136227240935857.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913623:  70%|#######   | 7/10 [00:03<00:01,  2.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  70%|#######   | 7/10 [00:03<00:01,  2.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  80%|########  | 8/10 [00:03<00:00,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:15,857]\u001b[0m Trial 34 finished with value: 0.9143841797712249 and parameters: {'bagging_fraction': 0.619470820975251, 'bagging_freq': 7}. Best is trial 34 with value: 0.9143841797712249.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  80%|########  | 8/10 [00:03<00:00,  2.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  80%|########  | 8/10 [00:04<00:00,  2.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  90%|######### | 9/10 [00:04<00:00,  2.12it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:16,354]\u001b[0m Trial 35 finished with value: 0.9131432890372944 and parameters: {'bagging_fraction': 0.9562264905501527, 'bagging_freq': 3}. Best is trial 34 with value: 0.9143841797712249.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914384:  90%|######### | 9/10 [00:04<00:00,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914565:  90%|######### | 9/10 [00:04<00:00,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.914565: 100%|##########| 10/10 [00:04<00:00,  1.96it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:16,950]\u001b[0m Trial 36 finished with value: 0.9145646729688874 and parameters: {'bagging_fraction': 0.6493593458472748, 'bagging_freq': 6}. Best is trial 36 with value: 0.9145646729688874.\u001b[0m\n",
      "bagging, val_score: 0.914565: 100%|##########| 10/10 [00:04<00:00,  2.07it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  17%|#6        | 1/6 [00:00<00:01,  2.57it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:17,380]\u001b[0m Trial 37 finished with value: 0.9135832412065971 and parameters: {'feature_fraction': 0.82}. Best is trial 37 with value: 0.9135832412065971.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  17%|#6        | 1/6 [00:00<00:01,  2.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  17%|#6        | 1/6 [00:00<00:01,  2.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  33%|###3      | 2/6 [00:00<00:02,  1.97it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:17,965]\u001b[0m Trial 38 finished with value: 0.9145646729688874 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 38 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  33%|###3      | 2/6 [00:01<00:02,  1.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  33%|###3      | 2/6 [00:01<00:02,  1.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  50%|#####     | 3/6 [00:01<00:01,  2.06it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:18,432]\u001b[0m Trial 39 finished with value: 0.913777835435327 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 38 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  50%|#####     | 3/6 [00:01<00:01,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  50%|#####     | 3/6 [00:01<00:01,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  67%|######6   | 4/6 [00:01<00:00,  2.21it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:18,825]\u001b[0m Trial 40 finished with value: 0.9135832412065971 and parameters: {'feature_fraction': 0.852}. Best is trial 38 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  67%|######6   | 4/6 [00:01<00:00,  2.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  67%|######6   | 4/6 [00:02<00:00,  2.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [1:36:04<?, ?it/s]<00:00,  2.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [1:36:26<?, ?it/s]\n",
      "\u001b[32m[I 2021-02-16 23:04:19,567]\u001b[0m Trial 41 finished with value: 0.9145646729688874 and parameters: {'feature_fraction': 0.948}. Best is trial 38 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  83%|########3 | 5/6 [00:02<00:00,  2.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565:  83%|########3 | 5/6 [00:03<00:00,  2.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.914565: 100%|##########| 6/6 [00:03<00:00,  1.75it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:04:20,117]\u001b[0m Trial 42 finished with value: 0.9145646729688874 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 38 with value: 0.9145646729688874.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.914565: 100%|##########| 6/6 [00:03<00:00,  1.90it/s]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:   5%|5         | 1/20 [00:00<00:10,  1.73it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:20,719]\u001b[0m Trial 43 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 2.1225696912962914e-05, 'lambda_l2': 1.064154487307997e-08}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:   5%|5         | 1/20 [00:00<00:10,  1.73it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:   5%|5         | 1/20 [00:01<00:10,  1.73it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  10%|#         | 2/20 [00:01<00:08,  2.03it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:21,153]\u001b[0m Trial 44 finished with value: 0.913653746361934 and parameters: {'lambda_l1': 0.003413358277328683, 'lambda_l2': 0.5781534458932064}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  10%|#         | 2/20 [00:01<00:08,  2.03it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  10%|#         | 2/20 [00:01<00:08,  2.03it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  15%|#5        | 3/20 [00:01<00:09,  1.88it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:21,730]\u001b[0m Trial 45 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 0.0021708576475701507, 'lambda_l2': 0.0006713363364549579}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  15%|#5        | 3/20 [00:01<00:09,  1.88it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  15%|#5        | 3/20 [00:02<00:09,  1.88it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  20%|##        | 4/20 [00:02<00:08,  1.94it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:22,225]\u001b[0m Trial 46 finished with value: 0.9136001624438779 and parameters: {'lambda_l1': 0.04541338624621278, 'lambda_l2': 0.00015689301758076659}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  20%|##        | 4/20 [00:02<00:08,  1.94it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  20%|##        | 4/20 [00:02<00:08,  1.94it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  25%|##5       | 5/20 [00:02<00:07,  2.05it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:22,657]\u001b[0m Trial 47 finished with value: 0.913529657288541 and parameters: {'lambda_l1': 0.24034509492107023, 'lambda_l2': 2.3935295277893827e-06}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  25%|##5       | 5/20 [00:02<00:07,  2.05it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  25%|##5       | 5/20 [00:02<00:07,  2.05it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  30%|###       | 6/20 [00:02<00:06,  2.11it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:23,109]\u001b[0m Trial 48 finished with value: 0.9137270717234844 and parameters: {'lambda_l1': 0.45284111068877414, 'lambda_l2': 0.005167221191508403}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  30%|###       | 6/20 [00:02<00:06,  2.11it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  30%|###       | 6/20 [00:03<00:06,  2.11it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  35%|###5      | 7/20 [00:03<00:06,  1.96it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:23,696]\u001b[0m Trial 49 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 1.1037677226173206e-05, 'lambda_l2': 4.894441004032804e-05}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  35%|###5      | 7/20 [00:03<00:06,  1.96it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  35%|###5      | 7/20 [00:04<00:06,  1.96it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  40%|####      | 8/20 [00:04<00:06,  1.90it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:24,259]\u001b[0m Trial 50 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 4.8552636314503e-05, 'lambda_l2': 3.4269960623471224e-06}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  40%|####      | 8/20 [00:04<00:06,  1.90it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  40%|####      | 8/20 [00:04<00:06,  1.90it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  45%|####5     | 9/20 [00:04<00:05,  1.87it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:24,810]\u001b[0m Trial 51 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 4.240397575446638e-06, 'lambda_l2': 1.3004876047227733e-07}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  45%|####5     | 9/20 [00:04<00:05,  1.87it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  45%|####5     | 9/20 [00:05<00:05,  1.87it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  50%|#####     | 10/20 [00:05<00:05,  1.83it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:25,379]\u001b[0m Trial 52 finished with value: 0.9142685513164722 and parameters: {'lambda_l1': 0.015038534487283482, 'lambda_l2': 0.002335275834736409}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  50%|#####     | 10/20 [00:05<00:05,  1.83it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  50%|#####     | 10/20 [00:05<00:05,  1.83it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  55%|#####5    | 11/20 [00:05<00:04,  1.82it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:25,933]\u001b[0m Trial 53 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 1.2667160341249133e-08, 'lambda_l2': 1.0558670613355198e-08}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  55%|#####5    | 11/20 [00:05<00:04,  1.82it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  55%|#####5    | 11/20 [00:06<00:04,  1.82it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  60%|######    | 12/20 [00:06<00:04,  1.98it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:26,335]\u001b[0m Trial 54 finished with value: 0.9129684362520587 and parameters: {'lambda_l1': 1.0219213349312023e-07, 'lambda_l2': 0.11212251524969342}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  60%|######    | 12/20 [00:06<00:04,  1.98it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  60%|######    | 12/20 [00:06<00:04,  1.98it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  65%|######5   | 13/20 [00:06<00:03,  1.89it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:26,926]\u001b[0m Trial 55 finished with value: 0.9142685513164722 and parameters: {'lambda_l1': 0.0004777772525638474, 'lambda_l2': 0.01776125594837092}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  65%|######5   | 13/20 [00:06<00:03,  1.89it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  65%|######5   | 13/20 [00:07<00:03,  1.89it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  70%|#######   | 14/20 [00:07<00:03,  1.83it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:27,506]\u001b[0m Trial 56 finished with value: 0.9138850032714392 and parameters: {'lambda_l1': 8.642225751893066e-07, 'lambda_l2': 8.34355339507452}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  70%|#######   | 14/20 [00:07<00:03,  1.83it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  70%|#######   | 14/20 [00:07<00:03,  1.83it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  75%|#######5  | 15/20 [00:07<00:02,  1.78it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:28,107]\u001b[0m Trial 57 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 0.00032168485925903364, 'lambda_l2': 2.7206866045047627e-05}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  75%|#######5  | 15/20 [00:07<00:02,  1.78it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  75%|#######5  | 15/20 [00:08<00:02,  1.78it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  80%|########  | 16/20 [00:08<00:02,  1.69it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:28,769]\u001b[0m Trial 58 finished with value: 0.9133294226473839 and parameters: {'lambda_l1': 9.591132950625946, 'lambda_l2': 1.8045665185479666e-08}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  80%|########  | 16/20 [00:08<00:02,  1.69it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  80%|########  | 16/20 [00:09<00:02,  1.69it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  85%|########5 | 17/20 [00:09<00:01,  1.67it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:29,384]\u001b[0m Trial 59 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 0.001669808180586382, 'lambda_l2': 0.0010126440593310846}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  85%|########5 | 17/20 [00:09<00:01,  1.67it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  85%|########5 | 17/20 [00:09<00:01,  1.67it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  90%|######### | 18/20 [00:09<00:01,  1.69it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:29,971]\u001b[0m Trial 60 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 7.099510807745102e-05, 'lambda_l2': 1.7063897490804091e-06}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  90%|######### | 18/20 [00:09<00:01,  1.69it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  90%|######### | 18/20 [00:10<00:01,  1.69it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  95%|#########5| 19/20 [00:10<00:00,  1.67it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:30,573]\u001b[0m Trial 61 finished with value: 0.9145646729688874 and parameters: {'lambda_l1': 1.0332095630934186e-06, 'lambda_l2': 1.6474783509497238e-07}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.914565:  95%|#########5| 19/20 [00:10<00:00,  1.67it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565:  95%|#########5| 19/20 [00:10<00:00,  1.67it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.914565: 100%|##########| 20/20 [00:10<00:00,  1.75it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:31,084]\u001b[0m Trial 62 finished with value: 0.9136227240935857 and parameters: {'lambda_l1': 3.884436909605799e-05, 'lambda_l2': 0.05300256163671352}. Best is trial 43 with value: 0.9145646729688874.\u001b[0m\n",
      "regularization_factors, val_score: 0.914565: 100%|##########| 20/20 [00:10<00:00,  1.83it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  20%|##        | 1/5 [00:00<00:01,  2.09it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:31,601]\u001b[0m Trial 63 finished with value: 0.9135973422376644 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.9135973422376644.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914565:  20%|##        | 1/5 [00:00<00:01,  2.09it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  20%|##        | 1/5 [00:01<00:01,  2.09it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  40%|####      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:32,382]\u001b[0m Trial 64 finished with value: 0.9144208424520001 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.9144208424520001.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914565:  40%|####      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  40%|####      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  60%|######    | 3/5 [00:01<00:01,  1.68it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:32,912]\u001b[0m Trial 65 finished with value: 0.9131461092435079 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.9144208424520001.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914565:  60%|######    | 3/5 [00:01<00:01,  1.68it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  60%|######    | 3/5 [00:02<00:01,  1.68it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  80%|########  | 4/5 [00:02<00:00,  1.54it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:33,638]\u001b[0m Trial 66 finished with value: 0.9139047447149335 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.9144208424520001.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914565:  80%|########  | 4/5 [00:02<00:00,  1.54it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565:  80%|########  | 4/5 [00:03<00:00,  1.54it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.914565: 100%|##########| 5/5 [00:03<00:00,  1.66it/s]\u001b[A\u001b[32m[I 2021-02-16 23:04:34,150]\u001b[0m Trial 67 finished with value: 0.9132307154299122 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.9144208424520001.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.914565: 100%|##########| 5/5 [00:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 3, 'feature_fraction': 0.8999999999999999, 'bagging_fraction': 0.6493593458472748, 'bagging_freq': 6, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100, 'categorical_column': [1, 2, 4, 5, 6, 7, 8]}\n",
      "  Accuracy = 0.8476890756302521\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: auc\n",
      "    boosting_type: gbdt\n",
      "    verbosity: -1\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 0.0\n",
      "    lambda_l2: 0.0\n",
      "    num_leaves: 3\n",
      "    feature_fraction: 0.8999999999999999\n",
      "    bagging_fraction: 0.6493593458472748\n",
      "    bagging_freq: 6\n",
      "    min_child_samples: 20\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 100\n",
      "    categorical_column: [1, 2, 4, 5, 6, 7, 8]\n",
      "398\n",
      "optimum_boost_rounds: 398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna.integration.lightgbm as optuna_lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "model = optuna_lgb.train(params, trains, valid_sets=valids,\n",
    "                    verbose_eval=False, num_boost_round=1000,early_stopping_rounds=100)\n",
    "\n",
    "prediction = np.rint(model.predict(X_valid, num_iteration=model.best_iteration))\n",
    "accuracy = accuracy_score(y_valid, prediction)\n",
    "\n",
    "best_params = model.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "print(model.best_iteration)\n",
    "optimum_boost_rounds = model.best_iteration\n",
    "print(\"optimum_boost_rounds: {}\".format(optimum_boost_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "numerous-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混同行列:\n",
      "[[1618  157]\n",
      " [ 211  394]]\n",
      "正解率(Accuracy):0.845\n",
      "適合率(Precision):0.715\n",
      "再現率(Recall):0.651\n",
      "F1値(Accuracy):0.682\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age-median</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num-median</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "occupation                   198\n",
       "age                          176\n",
       "education                    135\n",
       "workclass                     64\n",
       "education-num                 63\n",
       "marital-status                51\n",
       "relationship                  41\n",
       "race                          29\n",
       "age-median                    22\n",
       "sex                           12\n",
       "education-num-median           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "\n",
    "best_model = lgb.train(best_params, trains,valid_sets=valids,num_boost_round=optimum_boost_rounds,verbose_eval=False)\n",
    "y_pred = np.round(best_model.predict(X_test)).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#混同行列の作成\n",
    "matrix6 = confusion_matrix(y_test, y_pred)\n",
    "print(\"混同行列:\\n{}\".format(matrix6))\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(\"正解率(Accuracy):{:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"適合率(Precision):{:.3f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"再現率(Recall):{:.3f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1値(Accuracy):{:.3f}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "importance = pd.DataFrame(best_model.feature_importance(), index = X_train.columns, columns=[\"importance\"])\n",
    "display(importance.sort_values(\"importance\", ascending= False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-recipient",
   "metadata": {},
   "source": [
    "### アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "promising-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>pred11</th>\n",
       "      <th>pred12</th>\n",
       "      <th>pred13</th>\n",
       "      <th>pred14</th>\n",
       "      <th>pred15</th>\n",
       "      <th>pred16</th>\n",
       "      <th>pred17</th>\n",
       "      <th>pred18</th>\n",
       "      <th>pred19</th>\n",
       "      <th>pred20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
       "0      1      1      1      1      1      1      1      1      1       1   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "2      0      0      0      0      0      0      0      0      0       0   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      1      1      1      1      1      1      1       1   \n",
       "\n",
       "   pred11  pred12  pred13  pred14  pred15  pred16  pred17  pred18  pred19  \\\n",
       "0       1       1       1       1       1       1       1       1       1   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       1       1       1       1       1       1       1       1       1   \n",
       "\n",
       "   pred20  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "output_result = pd.DataFrame()\n",
    "for _ in range(20):\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(base_train.iloc[:,:-1],base_train.iloc[:,-1], random_state=_, test_size=0.2)\n",
    "    \n",
    "    trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "    \n",
    "    model = lgb.train(best_params, trains,valid_sets=valids,num_boost_round=optimum_boost_rounds,verbose_eval=False)\n",
    "    pred = np.round(best_model.predict(base_test)).astype(int)\n",
    "    \n",
    "    output = pd.DataFrame(pred,columns=['pred' + str(_+1)])\n",
    "    #各予測結果を格納\n",
    "    if _ == 0:\n",
    "        output_result = output\n",
    "    else:\n",
    "        output_result = pd.concat([output_result,output],axis=1)\n",
    "        \n",
    "output_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "sufficient-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = np.round(output_result.mean(axis='columns')).astype(int)\n",
    "\n",
    "_test = pd.read_csv('data/test2.csv')\n",
    "df_result = pd.concat([_test['index'],df_mean],axis=1)\n",
    "\n",
    "df_result.to_csv('data/submit2.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cardiac-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>pred11</th>\n",
       "      <th>pred12</th>\n",
       "      <th>pred13</th>\n",
       "      <th>pred14</th>\n",
       "      <th>pred15</th>\n",
       "      <th>pred16</th>\n",
       "      <th>pred17</th>\n",
       "      <th>pred18</th>\n",
       "      <th>pred19</th>\n",
       "      <th>pred20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>0.234314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.423611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred1        pred2        pred3        pred4        pred5  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.234314     0.234314     0.234314     0.234314     0.234314   \n",
       "std       0.423611     0.423611     0.423611     0.423611     0.423611   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             pred6        pred7        pred8        pred9       pred10  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.234314     0.234314     0.234314     0.234314     0.234314   \n",
       "std       0.423611     0.423611     0.423611     0.423611     0.423611   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            pred11       pred12       pred13       pred14       pred15  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.234314     0.234314     0.234314     0.234314     0.234314   \n",
       "std       0.423611     0.423611     0.423611     0.423611     0.423611   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            pred16       pred17       pred18       pred19       pred20  \n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000  \n",
       "mean      0.234314     0.234314     0.234314     0.234314     0.234314  \n",
       "std       0.423611     0.423611     0.423611     0.423611     0.423611  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-accommodation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
