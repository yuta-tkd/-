{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "golden-pulse",
   "metadata": {},
   "source": [
    "# lightGBM part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "waiting-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "skilled-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         441\n",
       "1         841\n",
       "2         361\n",
       "3         289\n",
       "4        2209\n",
       "         ... \n",
       "11895     529\n",
       "11896     961\n",
       "11897     441\n",
       "11898     841\n",
       "11899     289\n",
       "Name: age, Length: 11900, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(base_train['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "sapphire-charlotte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>age-median</th>\n",
       "      <th>age-mean</th>\n",
       "      <th>education-num-median</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-6.958319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.041681</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8.958319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-10.958319</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.041681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education-num  marital-status  occupation  \\\n",
       "0   21          3         13             10               0           1   \n",
       "1   29          3         10              9               0           1   \n",
       "2   19          3          9             13               2           8   \n",
       "3   17          3         10              9               2           2   \n",
       "4   47          3         13             10               1           2   \n",
       "\n",
       "   relationship  sex  age-median   age-mean  education-num-median  Y  \n",
       "0             3    0        -3.0  -6.958319                   0.0  0  \n",
       "1             1    0         5.0   1.041681                  -1.0  0  \n",
       "2             1    0        -5.0  -8.958319                   3.0  0  \n",
       "3             3    1        -7.0 -10.958319                  -1.0  0  \n",
       "4             0    1        23.0  19.041681                   0.0  0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train = pd.read_csv('data/train2.csv')\n",
    "base_test = pd.read_csv('data/test2.csv')\n",
    "\n",
    "base_train = base_train.drop('index', axis=1)\n",
    "base_train = base_train.drop('native-country', axis=1)\n",
    "base_train = base_train.drop('fnlwgt', axis=1)\n",
    "# base_train = base_train.drop('race', axis=1)\n",
    "\n",
    "base_test = base_test.drop('index', axis=1)\n",
    "base_test = base_test.drop('native-country', axis=1)\n",
    "base_test = base_test.drop('fnlwgt', axis=1)\n",
    "# base_test = base_test.drop('race', axis=1)\n",
    "\n",
    "\n",
    "# 特徴量の追加\n",
    "\n",
    "base_train['age-median'] = base_train['age'] - base_train['age'].median()\n",
    "# base_train['age-mean'] = base_train['age'] - base_train['age'].mean()\n",
    "# base_train['age-square'] = np.square(base_train['age'])\n",
    "base_train['education-num-median'] = base_train['education-num'] - base_train['education-num'].median()\n",
    "\n",
    "base_test['age-median'] = base_test['age'] - base_train['age'].median()\n",
    "# base_test['age-mean'] = base_test['age'] - base_train['age'].mean()\n",
    "# base_test['age-square'] = np.square(base_test['age'])\n",
    "base_test['education-num-median'] = base_test['education-num'] - base_train['education-num'].median()\n",
    "\n",
    "# \"Y\"の順序\n",
    "cols = base_train.columns.tolist()\n",
    "cols.remove(\"Y\")\n",
    "cols.append(\"Y\")\n",
    "base_train = base_train[cols]\n",
    "\n",
    "base_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "iraqi-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# categorical_features = [\"workclass\",\"fnlwgt\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n",
    "categorical_features = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\"]\n",
    "cat_columns = []\n",
    "for i,v in enumerate(base_train.columns):\n",
    "    if v in categorical_features:\n",
    "        cat_columns.append(i)\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-weather",
   "metadata": {},
   "source": [
    "### ハイパラメータ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "taken-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(base_train.iloc[:,:-1],base_train.iloc[:,-1], random_state=0, test_size=0.2)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "exclusive-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-16 23:02:25,438]\u001b[0m A new study created in memory with name: no-name-1d79683a-b495-4426-8322-cca49702896e\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: -inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.909017:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.909017:  14%|#4        | 1/7 [00:00<00:02,  2.82it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:25,821]\u001b[0m Trial 0 finished with value: 0.9090173273469756 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.9090173273469756.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.909017:  14%|#4        | 1/7 [00:00<00:02,  2.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  14%|#4        | 1/7 [00:00<00:02,  2.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  29%|##8       | 2/7 [00:00<00:01,  2.52it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:26,260]\u001b[0m Trial 1 finished with value: 0.9102582180809061 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  29%|##8       | 2/7 [00:00<00:01,  2.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  29%|##8       | 2/7 [00:01<00:01,  2.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  43%|####2     | 3/7 [00:01<00:01,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:26,650]\u001b[0m Trial 2 finished with value: 0.9085548135279652 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  43%|####2     | 3/7 [00:01<00:01,  2.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  43%|####2     | 3/7 [00:01<00:01,  2.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  57%|#####7    | 4/7 [00:01<00:01,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:27,125]\u001b[0m Trial 3 finished with value: 0.9097590415811204 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  57%|#####7    | 4/7 [00:01<00:01,  2.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  57%|#####7    | 4/7 [00:02<00:01,  2.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  71%|#######1  | 5/7 [00:02<00:00,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:27,547]\u001b[0m Trial 4 finished with value: 0.908642239920583 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  71%|#######1  | 5/7 [00:02<00:00,  2.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  71%|#######1  | 5/7 [00:02<00:00,  2.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  86%|########5 | 6/7 [00:02<00:00,  2.42it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:27,933]\u001b[0m Trial 5 finished with value: 0.909609570651806 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  86%|########5 | 6/7 [00:02<00:00,  2.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258:  86%|########5 | 6/7 [00:02<00:00,  2.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.910258: 100%|##########| 7/7 [00:02<00:00,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:28,298]\u001b[0m Trial 6 finished with value: 0.9093021681745369 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.9102582180809061.\u001b[0m\n",
      "feature_fraction, val_score: 0.910258: 100%|##########| 7/7 [00:02<00:00,  2.46it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:   5%|5         | 1/20 [00:00<00:14,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:29,109]\u001b[0m Trial 7 finished with value: 0.9069839586670577 and parameters: {'num_leaves': 124}. Best is trial 7 with value: 0.9069839586670577.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:   5%|5         | 1/20 [00:00<00:14,  1.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:   5%|5         | 1/20 [00:01<00:14,  1.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:  10%|#         | 2/20 [00:01<00:13,  1.32it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:29,850]\u001b[0m Trial 8 finished with value: 0.9052861945265438 and parameters: {'num_leaves': 256}. Best is trial 7 with value: 0.9069839586670577.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:  10%|#         | 2/20 [00:01<00:13,  1.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:  10%|#         | 2/20 [00:02<00:13,  1.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:30,497]\u001b[0m Trial 9 finished with value: 0.9057571689641947 and parameters: {'num_leaves': 132}. Best is trial 7 with value: 0.9069839586670577.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.910258:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  20%|##        | 4/20 [00:02<00:08,  1.82it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:30,798]\u001b[0m Trial 10 finished with value: 0.9116090968571622 and parameters: {'num_leaves': 9}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  20%|##        | 4/20 [00:02<00:08,  1.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  20%|##        | 4/20 [00:03<00:08,  1.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  25%|##5       | 5/20 [00:03<00:08,  1.70it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:31,461]\u001b[0m Trial 11 finished with value: 0.9052861945265438 and parameters: {'num_leaves': 235}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  25%|##5       | 5/20 [00:03<00:08,  1.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  25%|##5       | 5/20 [00:03<00:08,  1.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  30%|###       | 6/20 [00:03<00:08,  1.57it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:32,193]\u001b[0m Trial 12 finished with value: 0.9052805541141168 and parameters: {'num_leaves': 187}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  30%|###       | 6/20 [00:03<00:08,  1.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  30%|###       | 6/20 [00:04<00:08,  1.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  35%|###5      | 7/20 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:32,537]\u001b[0m Trial 13 finished with value: 0.9102469372560522 and parameters: {'num_leaves': 53}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  35%|###5      | 7/20 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  35%|###5      | 7/20 [00:04<00:07,  1.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  40%|####      | 8/20 [00:04<00:06,  1.82it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:33,095]\u001b[0m Trial 14 finished with value: 0.9055794959727456 and parameters: {'num_leaves': 148}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  40%|####      | 8/20 [00:04<00:06,  1.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  40%|####      | 8/20 [00:05<00:06,  1.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  45%|####5     | 9/20 [00:05<00:05,  2.06it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:33,447]\u001b[0m Trial 15 finished with value: 0.9093754935360874 and parameters: {'num_leaves': 26}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  45%|####5     | 9/20 [00:05<00:05,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  45%|####5     | 9/20 [00:05<00:05,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  50%|#####     | 10/20 [00:05<00:05,  1.99it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:33,985]\u001b[0m Trial 16 finished with value: 0.9072377772262707 and parameters: {'num_leaves': 128}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  50%|#####     | 10/20 [00:05<00:05,  1.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  50%|#####     | 10/20 [00:06<00:05,  1.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  55%|#####5    | 11/20 [00:06<00:04,  2.06it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:34,436]\u001b[0m Trial 17 finished with value: 0.9113947611849379 and parameters: {'num_leaves': 5}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  55%|#####5    | 11/20 [00:06<00:04,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  55%|#####5    | 11/20 [00:06<00:04,  2.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  60%|######    | 12/20 [00:06<00:03,  2.20it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:34,823]\u001b[0m Trial 18 finished with value: 0.9112227286059157 and parameters: {'num_leaves': 7}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  60%|######    | 12/20 [00:06<00:03,  2.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  60%|######    | 12/20 [00:06<00:03,  2.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  65%|######5   | 13/20 [00:06<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:35,260]\u001b[0m Trial 19 finished with value: 0.9059292015432169 and parameters: {'num_leaves': 76}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  65%|######5   | 13/20 [00:06<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  65%|######5   | 13/20 [00:07<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  70%|#######   | 14/20 [00:07<00:02,  2.13it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:35,765]\u001b[0m Trial 20 finished with value: 0.9114342440719265 and parameters: {'num_leaves': 4}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  70%|#######   | 14/20 [00:07<00:02,  2.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  70%|#######   | 14/20 [00:07<00:02,  2.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  75%|#######5  | 15/20 [00:07<00:02,  2.11it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:36,250]\u001b[0m Trial 21 finished with value: 0.9079456489858538 and parameters: {'num_leaves': 67}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  75%|#######5  | 15/20 [00:07<00:02,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  75%|#######5  | 15/20 [00:08<00:02,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  80%|########  | 16/20 [00:08<00:01,  2.31it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:36,587]\u001b[0m Trial 22 finished with value: 0.9102582180809061 and parameters: {'num_leaves': 31}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  80%|########  | 16/20 [00:08<00:01,  2.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  80%|########  | 16/20 [00:08<00:01,  2.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  85%|########5 | 17/20 [00:08<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:37,093]\u001b[0m Trial 23 finished with value: 0.9047644563770503 and parameters: {'num_leaves': 90}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  85%|########5 | 17/20 [00:08<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  85%|########5 | 17/20 [00:09<00:01,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  90%|######### | 18/20 [00:09<00:01,  1.87it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:37,822]\u001b[0m Trial 24 finished with value: 0.91104787582068 and parameters: {'num_leaves': 2}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  90%|######### | 18/20 [00:09<00:01,  1.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  90%|######### | 18/20 [00:09<00:01,  1.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  95%|#########5| 19/20 [00:09<00:00,  2.11it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:38,152]\u001b[0m Trial 25 finished with value: 0.908901698892223 and parameters: {'num_leaves': 39}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  95%|#########5| 19/20 [00:09<00:00,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609:  95%|#########5| 19/20 [00:10<00:00,  2.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.911609: 100%|##########| 20/20 [00:10<00:00,  2.10it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:38,630]\u001b[0m Trial 26 finished with value: 0.9060702118538908 and parameters: {'num_leaves': 101}. Best is trial 10 with value: 0.9116090968571622.\u001b[0m\n",
      "num_leaves, val_score: 0.911609: 100%|##########| 20/20 [00:10<00:00,  1.94it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911609:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911609:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911609:  10%|#         | 1/10 [00:00<00:03,  2.91it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:39,003]\u001b[0m Trial 27 finished with value: 0.9114709067527017 and parameters: {'bagging_fraction': 0.7566449669256785, 'bagging_freq': 7}. Best is trial 27 with value: 0.9114709067527017.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911609:  10%|#         | 1/10 [00:00<00:03,  2.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  10%|#         | 1/10 [00:00<00:03,  2.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  20%|##        | 2/10 [00:00<00:02,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:39,394]\u001b[0m Trial 28 finished with value: 0.9117190848994878 and parameters: {'bagging_fraction': 0.746597436507104, 'bagging_freq': 2}. Best is trial 28 with value: 0.9117190848994878.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  20%|##        | 2/10 [00:00<00:02,  2.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  20%|##        | 2/10 [00:01<00:02,  2.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  30%|###       | 3/10 [00:01<00:02,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:39,795]\u001b[0m Trial 29 finished with value: 0.9111776053065 and parameters: {'bagging_fraction': 0.9551132611769576, 'bagging_freq': 2}. Best is trial 28 with value: 0.9117190848994878.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  30%|###       | 3/10 [00:01<00:02,  2.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  30%|###       | 3/10 [00:01<00:02,  2.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  40%|####      | 4/10 [00:01<00:02,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:40,283]\u001b[0m Trial 30 finished with value: 0.9091132143582339 and parameters: {'bagging_fraction': 0.5081616947194845, 'bagging_freq': 4}. Best is trial 28 with value: 0.9117190848994878.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  40%|####      | 4/10 [00:01<00:02,  2.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  40%|####      | 4/10 [00:01<00:02,  2.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  50%|#####     | 5/10 [00:01<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:40,563]\u001b[0m Trial 31 finished with value: 0.9107179116937031 and parameters: {'bagging_fraction': 0.5415399018597088, 'bagging_freq': 7}. Best is trial 28 with value: 0.9117190848994878.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911719:  50%|#####     | 5/10 [00:01<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  50%|#####     | 5/10 [00:02<00:01,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  60%|######    | 6/10 [00:02<00:01,  2.72it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:40,921]\u001b[0m Trial 32 finished with value: 0.911902398303364 and parameters: {'bagging_fraction': 0.7274132300609046, 'bagging_freq': 1}. Best is trial 32 with value: 0.911902398303364.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  60%|######    | 6/10 [00:02<00:01,  2.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  60%|######    | 6/10 [00:02<00:01,  2.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  70%|#######   | 7/10 [00:02<00:01,  2.85it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:41,237]\u001b[0m Trial 33 finished with value: 0.9107602147869052 and parameters: {'bagging_fraction': 0.8433058721336915, 'bagging_freq': 1}. Best is trial 32 with value: 0.911902398303364.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911902:  70%|#######   | 7/10 [00:02<00:01,  2.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911939:  70%|#######   | 7/10 [00:03<00:01,  2.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911939:  80%|########  | 8/10 [00:03<00:00,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:41,727]\u001b[0m Trial 34 finished with value: 0.9119390609841391 and parameters: {'bagging_fraction': 0.7545918446364492, 'bagging_freq': 6}. Best is trial 34 with value: 0.9119390609841391.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.911939:  80%|########  | 8/10 [00:03<00:00,  2.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.912444:  80%|########  | 8/10 [00:03<00:00,  2.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.912444:  90%|######### | 9/10 [00:03<00:00,  2.33it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:42,231]\u001b[0m Trial 35 finished with value: 0.9124438778963517 and parameters: {'bagging_fraction': 0.8960759611925917, 'bagging_freq': 7}. Best is trial 35 with value: 0.9124438778963517.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.912444:  90%|######### | 9/10 [00:03<00:00,  2.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913716:  90%|######### | 9/10 [00:04<00:00,  2.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "bagging, val_score: 0.913716: 100%|##########| 10/10 [00:04<00:00,  2.07it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:42,824]\u001b[0m Trial 36 finished with value: 0.9137157908986305 and parameters: {'bagging_fraction': 0.5149101746240803, 'bagging_freq': 2}. Best is trial 36 with value: 0.9137157908986305.\u001b[0m\n",
      "bagging, val_score: 0.913716: 100%|##########| 10/10 [00:04<00:00,  2.39it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  17%|#6        | 1/6 [00:00<00:02,  1.84it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:43,432]\u001b[0m Trial 37 finished with value: 0.9124833607833405 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 37 with value: 0.9124833607833405.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  17%|#6        | 1/6 [00:00<00:02,  1.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  17%|#6        | 1/6 [00:01<00:02,  1.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  33%|###3      | 2/6 [00:01<00:02,  1.95it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:43,916]\u001b[0m Trial 38 finished with value: 0.9137157908986305 and parameters: {'feature_fraction': 0.948}. Best is trial 38 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  33%|###3      | 2/6 [00:01<00:02,  1.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  33%|###3      | 2/6 [00:01<00:02,  1.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  50%|#####     | 3/6 [00:01<00:01,  2.14it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:44,308]\u001b[0m Trial 39 finished with value: 0.9137157908986305 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 38 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  50%|#####     | 3/6 [00:01<00:01,  2.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  50%|#####     | 3/6 [00:01<00:01,  2.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  67%|######6   | 4/6 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:44,700]\u001b[0m Trial 40 finished with value: 0.9137157908986305 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 38 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  67%|######6   | 4/6 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  67%|######6   | 4/6 [00:02<00:00,  2.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  83%|########3 | 5/6 [00:02<00:00,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:45,109]\u001b[0m Trial 41 finished with value: 0.9123423504726665 and parameters: {'feature_fraction': 0.82}. Best is trial 38 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  83%|########3 | 5/6 [00:02<00:00,  2.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716:  83%|########3 | 5/6 [00:02<00:00,  2.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.913716: 100%|##########| 6/6 [00:02<00:00,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:45,497]\u001b[0m Trial 42 finished with value: 0.9123423504726665 and parameters: {'feature_fraction': 0.852}. Best is trial 38 with value: 0.9137157908986305.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.913716: 100%|##########| 6/6 [00:02<00:00,  2.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:   5%|5         | 1/20 [00:00<00:06,  2.73it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:45,885]\u001b[0m Trial 43 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 1.4076340587203034e-06, 'lambda_l2': 7.903587309498349e-06}. Best is trial 43 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:   5%|5         | 1/20 [00:00<00:06,  2.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:   5%|5         | 1/20 [00:00<00:06,  2.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:  10%|#         | 2/20 [00:00<00:06,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:46,257]\u001b[0m Trial 44 finished with value: 0.913069963675744 and parameters: {'lambda_l1': 0.12169627263739322, 'lambda_l2': 4.698664243767317e-05}. Best is trial 43 with value: 0.9137157908986305.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913716:  10%|#         | 2/20 [00:00<00:06,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  10%|#         | 2/20 [00:01<00:06,  2.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  15%|#5        | 3/20 [00:01<00:06,  2.70it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:46,631]\u001b[0m Trial 45 finished with value: 0.9139188457460009 and parameters: {'lambda_l1': 0.0028820915140334163, 'lambda_l2': 4.377928538134716e-06}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  15%|#5        | 3/20 [00:01<00:06,  2.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  15%|#5        | 3/20 [00:01<00:06,  2.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  20%|##        | 4/20 [00:01<00:06,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:47,057]\u001b[0m Trial 46 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 5.748462536746485e-05, 'lambda_l2': 1.2718775656142949e-06}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  20%|##        | 4/20 [00:01<00:06,  2.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  20%|##        | 4/20 [00:01<00:06,  2.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  25%|##5       | 5/20 [00:01<00:05,  2.56it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:47,442]\u001b[0m Trial 47 finished with value: 0.9129317735712835 and parameters: {'lambda_l1': 0.09245807222293695, 'lambda_l2': 2.0678114161099632e-05}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  25%|##5       | 5/20 [00:01<00:05,  2.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  25%|##5       | 5/20 [00:02<00:05,  2.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  30%|###       | 6/20 [00:02<00:05,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:47,814]\u001b[0m Trial 48 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 6.904611155394145e-05, 'lambda_l2': 0.006268152709023028}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  30%|###       | 6/20 [00:02<00:05,  2.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  30%|###       | 6/20 [00:02<00:05,  2.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  35%|###5      | 7/20 [00:02<00:04,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:48,197]\u001b[0m Trial 49 finished with value: 0.9129092119215757 and parameters: {'lambda_l1': 0.013114655492491955, 'lambda_l2': 2.9085123616215977e-06}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  35%|###5      | 7/20 [00:02<00:04,  2.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  35%|###5      | 7/20 [00:03<00:04,  2.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  40%|####      | 8/20 [00:03<00:04,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:48,642]\u001b[0m Trial 50 finished with value: 0.9131179071813731 and parameters: {'lambda_l1': 4.135212223988184, 'lambda_l2': 0.0005893859375098276}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  40%|####      | 8/20 [00:03<00:04,  2.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  40%|####      | 8/20 [00:03<00:04,  2.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  45%|####5     | 9/20 [00:03<00:04,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:49,032]\u001b[0m Trial 51 finished with value: 0.9126187306815874 and parameters: {'lambda_l1': 0.09728202507795003, 'lambda_l2': 0.007688232693193168}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  45%|####5     | 9/20 [00:03<00:04,  2.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  45%|####5     | 9/20 [00:03<00:04,  2.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  50%|#####     | 10/20 [00:03<00:04,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:49,468]\u001b[0m Trial 52 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 2.812259048643601e-08, 'lambda_l2': 1.3241728621743935e-08}. Best is trial 45 with value: 0.9139188457460009.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.913919:  50%|#####     | 10/20 [00:03<00:04,  2.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  50%|#####     | 10/20 [00:04<00:04,  2.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  55%|#####5    | 11/20 [00:04<00:03,  2.31it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:49,952]\u001b[0m Trial 53 finished with value: 0.9141275410057983 and parameters: {'lambda_l1': 0.0015385651121905405, 'lambda_l2': 1.6288394629426697}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  55%|#####5    | 11/20 [00:04<00:03,  2.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  55%|#####5    | 11/20 [00:04<00:03,  2.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  60%|######    | 12/20 [00:04<00:03,  2.27it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:50,410]\u001b[0m Trial 54 finished with value: 0.9121872391309253 and parameters: {'lambda_l1': 0.0007517079646802786, 'lambda_l2': 3.59309877126957}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  60%|######    | 12/20 [00:04<00:03,  2.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  60%|######    | 12/20 [00:05<00:03,  2.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  65%|######5   | 13/20 [00:05<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:50,882]\u001b[0m Trial 55 finished with value: 0.9120208469643301 and parameters: {'lambda_l1': 0.0013498904569176895, 'lambda_l2': 0.6418396235653848}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  65%|######5   | 13/20 [00:05<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  65%|######5   | 13/20 [00:05<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  70%|#######   | 14/20 [00:05<00:02,  2.32it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:51,268]\u001b[0m Trial 56 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 3.2503417447519084e-06, 'lambda_l2': 4.462020610162319e-08}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  70%|#######   | 14/20 [00:05<00:02,  2.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  70%|#######   | 14/20 [00:06<00:02,  2.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  75%|#######5  | 15/20 [00:06<00:02,  2.03it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:51,898]\u001b[0m Trial 57 finished with value: 0.9124128556280036 and parameters: {'lambda_l1': 7.059678228908675, 'lambda_l2': 2.548745397441406e-07}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  75%|#######5  | 15/20 [00:06<00:02,  2.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  75%|#######5  | 15/20 [00:06<00:02,  2.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  80%|########  | 16/20 [00:06<00:01,  2.17it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:52,287]\u001b[0m Trial 58 finished with value: 0.9115921756198814 and parameters: {'lambda_l1': 0.004028559138847265, 'lambda_l2': 0.22986438498002787}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  80%|########  | 16/20 [00:06<00:01,  2.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  80%|########  | 16/20 [00:07<00:01,  2.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  85%|########5 | 17/20 [00:07<00:01,  2.28it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:52,673]\u001b[0m Trial 59 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 1.1445843020517065e-05, 'lambda_l2': 0.0006815590666548659}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  85%|########5 | 17/20 [00:07<00:01,  2.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  85%|########5 | 17/20 [00:07<00:01,  2.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  90%|######### | 18/20 [00:07<00:00,  2.28it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:53,114]\u001b[0m Trial 60 finished with value: 0.9138342395595966 and parameters: {'lambda_l1': 1.2635888631648768e-07, 'lambda_l2': 0.010402312804235795}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  90%|######### | 18/20 [00:07<00:00,  2.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  90%|######### | 18/20 [00:07<00:00,  2.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  95%|#########5| 19/20 [00:07<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:53,490]\u001b[0m Trial 61 finished with value: 0.9137157908986305 and parameters: {'lambda_l1': 0.00018926474509322296, 'lambda_l2': 2.5961308904016775e-07}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  95%|#########5| 19/20 [00:07<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128:  95%|#########5| 19/20 [00:08<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.914128: 100%|##########| 20/20 [00:08<00:00,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:53,866]\u001b[0m Trial 62 finished with value: 0.9128922906842948 and parameters: {'lambda_l1': 0.01499779437248218, 'lambda_l2': 8.184660454511216e-05}. Best is trial 53 with value: 0.9141275410057983.\u001b[0m\n",
      "regularization_factors, val_score: 0.914128: 100%|##########| 20/20 [00:08<00:00,  2.39it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  20%|##        | 1/5 [00:00<00:01,  2.46it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:54,326]\u001b[0m Trial 63 finished with value: 0.9115132098459039 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.9115132098459039.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  20%|##        | 1/5 [00:00<00:01,  2.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  20%|##        | 1/5 [00:00<00:01,  2.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  40%|####      | 2/5 [00:00<00:01,  2.48it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:54,722]\u001b[0m Trial 64 finished with value: 0.9140654964691018 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.9140654964691018.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  40%|####      | 2/5 [00:00<00:01,  2.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  40%|####      | 2/5 [00:01<00:01,  2.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  60%|######    | 3/5 [00:01<00:00,  2.34it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:55,178]\u001b[0m Trial 65 finished with value: 0.9121787785122848 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.9140654964691018.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  60%|######    | 3/5 [00:01<00:00,  2.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  60%|######    | 3/5 [00:01<00:00,  2.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  80%|########  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:55,587]\u001b[0m Trial 66 finished with value: 0.9123395302664531 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.9140654964691018.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  80%|########  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128:  80%|########  | 4/5 [00:02<00:00,  2.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.914128: 100%|##########| 5/5 [00:02<00:00,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-02-16 23:02:55,928]\u001b[0m Trial 67 finished with value: 0.9125905286194527 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.9140654964691018.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.914128: 100%|##########| 5/5 [00:02<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 0.0015385651121905405, 'lambda_l2': 1.6288394629426697, 'num_leaves': 9, 'feature_fraction': 0.8999999999999999, 'bagging_fraction': 0.5149101746240803, 'bagging_freq': 2, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100, 'categorical_column': [1, 2, 4, 5, 6, 7]}\n",
      "  Accuracy = 0.8413865546218487\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: auc\n",
      "    boosting_type: gbdt\n",
      "    verbosity: -1\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 0.0015385651121905405\n",
      "    lambda_l2: 1.6288394629426697\n",
      "    num_leaves: 9\n",
      "    feature_fraction: 0.8999999999999999\n",
      "    bagging_fraction: 0.5149101746240803\n",
      "    bagging_freq: 2\n",
      "    min_child_samples: 20\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 100\n",
      "    categorical_column: [1, 2, 4, 5, 6, 7]\n",
      "89\n",
      "optimum_boost_rounds: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna.integration.lightgbm as optuna_lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "model = optuna_lgb.train(params, trains, valid_sets=valids,\n",
    "                    verbose_eval=False, num_boost_round=1000,early_stopping_rounds=100)\n",
    "\n",
    "prediction = np.rint(model.predict(X_valid, num_iteration=model.best_iteration))\n",
    "accuracy = accuracy_score(y_valid, prediction)\n",
    "\n",
    "best_params = model.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "print(model.best_iteration)\n",
    "optimum_boost_rounds = model.best_iteration\n",
    "print(\"optimum_boost_rounds: {}\".format(optimum_boost_rounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "equivalent-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混同行列:\n",
      "[[1619  156]\n",
      " [ 220  385]]\n",
      "正解率(Accuracy):0.842\n",
      "適合率(Precision):0.712\n",
      "再現率(Recall):0.636\n",
      "F1値(Accuracy):0.672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age-median</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num-median</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age-mean</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "age                          251\n",
       "occupation                   131\n",
       "education-num                 91\n",
       "education                     69\n",
       "marital-status                45\n",
       "workclass                     36\n",
       "relationship                  35\n",
       "age-median                    23\n",
       "sex                           17\n",
       "education-num-median          14\n",
       "age-mean                       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "\n",
    "best_model = lgb.train(best_params, trains,valid_sets=valids,num_boost_round=optimum_boost_rounds,verbose_eval=False)\n",
    "y_pred = np.round(best_model.predict(X_test)).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#混同行列の作成\n",
    "matrix6 = confusion_matrix(y_test, y_pred)\n",
    "print(\"混同行列:\\n{}\".format(matrix6))\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "print(\"正解率(Accuracy):{:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"適合率(Precision):{:.3f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"再現率(Recall):{:.3f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F1値(Accuracy):{:.3f}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "importance = pd.DataFrame(best_model.feature_importance(), index = X_train.columns, columns=[\"importance\"])\n",
    "display(importance.sort_values(\"importance\", ascending= False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-element",
   "metadata": {},
   "source": [
    "### アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "clean-screen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>pred11</th>\n",
       "      <th>pred12</th>\n",
       "      <th>pred13</th>\n",
       "      <th>pred14</th>\n",
       "      <th>pred15</th>\n",
       "      <th>pred16</th>\n",
       "      <th>pred17</th>\n",
       "      <th>pred18</th>\n",
       "      <th>pred19</th>\n",
       "      <th>pred20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
       "0      1      1      1      1      1      1      1      1      1       1   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "2      0      0      0      0      0      0      0      0      0       0   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      1      1      1      1      1      1      1      1      1       1   \n",
       "\n",
       "   pred11  pred12  pred13  pred14  pred15  pred16  pred17  pred18  pred19  \\\n",
       "0       1       1       1       1       1       1       1       1       1   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       1       1       1       1       1       1       1       1       1   \n",
       "\n",
       "   pred20  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "output_result = pd.DataFrame()\n",
    "for _ in range(20):\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(base_train.iloc[:,:-1],base_train.iloc[:,-1], random_state=_, test_size=0.2)\n",
    "    \n",
    "    trains = lgb.Dataset(X_train, y_train,categorical_feature=categorical_features)\n",
    "    valids = lgb.Dataset(X_valid, y_valid,categorical_feature=categorical_features)\n",
    "    \n",
    "    model = lgb.train(best_params, trains,valid_sets=valids,num_boost_round=optimum_boost_rounds,verbose_eval=False)\n",
    "    pred = np.round(best_model.predict(base_test)).astype(int)\n",
    "    \n",
    "    output = pd.DataFrame(pred,columns=['pred' + str(_+1)])\n",
    "    #各予測結果を格納\n",
    "    if _ == 0:\n",
    "        output_result = output\n",
    "    else:\n",
    "        output_result = pd.concat([output_result,output],axis=1)\n",
    "        \n",
    "output_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "premium-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = np.round(output_result.mean(axis='columns')).astype(int)\n",
    "\n",
    "_test = pd.read_csv('data/test2.csv')\n",
    "df_result = pd.concat([_test['index'],df_mean],axis=1)\n",
    "\n",
    "df_result.to_csv('data/submit2.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "super-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>pred11</th>\n",
       "      <th>pred12</th>\n",
       "      <th>pred13</th>\n",
       "      <th>pred14</th>\n",
       "      <th>pred15</th>\n",
       "      <th>pred16</th>\n",
       "      <th>pred17</th>\n",
       "      <th>pred18</th>\n",
       "      <th>pred19</th>\n",
       "      <th>pred20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "      <td>0.236275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>0.424834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pred1        pred2        pred3        pred4        pred5  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.236275     0.236275     0.236275     0.236275     0.236275   \n",
       "std       0.424834     0.424834     0.424834     0.424834     0.424834   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             pred6        pred7        pred8        pred9       pred10  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.236275     0.236275     0.236275     0.236275     0.236275   \n",
       "std       0.424834     0.424834     0.424834     0.424834     0.424834   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            pred11       pred12       pred13       pred14       pred15  \\\n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000   \n",
       "mean      0.236275     0.236275     0.236275     0.236275     0.236275   \n",
       "std       0.424834     0.424834     0.424834     0.424834     0.424834   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            pred16       pred17       pred18       pred19       pred20  \n",
       "count  5100.000000  5100.000000  5100.000000  5100.000000  5100.000000  \n",
       "mean      0.236275     0.236275     0.236275     0.236275     0.236275  \n",
       "std       0.424834     0.424834     0.424834     0.424834     0.424834  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-tennessee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
